Before Cloud Computing
--------------------------------
1. Buy costly stack of servers
2. Varied Traffic ie server may be idle for most time or too busy at other time
3. Monitoring and Maintenance of servers


Service Models
--------------------
1. SaaS  ( Software as a Service )          ( Eg: Gmail )
    manage only Data by user , others like Application, Runtime, Middleware, OS, Servers, Storage etc... are maintained by vendor

2. PaaS  ( Platform as a Service )           ( Eg: Heroku , Google App Engine )
    manage Application and Data by user , others like Runtime, Middleware, OS, Servers, Storage etc... are maintained by vendor
    This is CLOUD HOSTING.

3. IaaS   ( Infrastructure as a Service )    ( Eg: AWS EC2 , Google Compute Engine (GCE) )
    manage Application, Data, Runtime, Middleware, OS by user , others like Servers, Storage etc... are maintained by vendor.
    This is CLOUD COMPUTING.


Cloud Native
----------------
Cloud native is an approach that uses technologies such as containers, Kubernetes, immutable infrastructure, and microservices
to develop scalable applications that are built to run in the cloud.
There are three key elements to any cloud-native architecture:
- It is containerized.
  Each part (applications, processes, etc.) is packaged in its own container. This facilitates reproducibility, transparency, and resource isolation.
- It is dynamically managed.
  Containers are actively orchestrated to optimize resource utilization.
- It is microservices-oriented.
  Applications are segmented into microservices, which significantly increases their overall agility and maintainability.


Deployment Models
-------------------------
1. Public Cloud
2. Private Cloud
3. Hybrid Cloud  ( Public + Private )


Cloud Providers
---------------------
1. GCP  ( Google Cloud Platform )
2. AWS  ( Amazon Web Services )
3. DigitalOcean
4. IBM Cloud
5. Microsoft Azure
6. terremark


Developer's     : job is to add new features.
Operations's    : job is to keep site stable and fast.
Tester's        : job is to reduce risk.

DevOps
            It solves customer problems
            It is for cloud
            It is a solution
            It is a tool
            It is a skill to master 

Agile breaks wall between Business and Development team.
DevOps breaks wall between Development and Operations team.

- Dev        : people involved in developing product.
- Ops        : system engineers, administrators, operations staff, release engineers, DBA, network engineers, security engineers.
- Agile      : collaboration of customers, product management, developers, QA
- DevOps     : extending principles of Agile to entire delivered service.
                      - improved deployment frequency.
                      - faster time to market.
                      - lower failure rate.
                      - shortened lead time between fixes.
                      - faster mean time to recovery in event of a new relaease crashing.
- CD          : Continuous Delivery
- CI          : Continuous Integration
- Lead time   : time between identification of requirement and it's fulfillment.
- Mean time to failure : time for which a system or application will last in operation.


DevOps practice involves
-----------------------------------
  PLAN --> CODE --> BUILD --> TEST --> INTEGRATE --> DEPLOY --> OPERATE --> MONITOR
- Continuous Development which needs Version control for all
- Automated and Continuous testing
- Proactive monitoring and metrics
- Configuration management
- Continuous Integration / Delivery / Deployment
- Virtualization / Coud / Containers
- Toolchain approach


DevOps tools
-------------------
Development
     Source Code Management or Continuous Development
           - Git
     Continuous Integration
           - Ant, Maven, Gradle    ( Build Automation tool ie download required dependencies )
           - Jenkins, Travis       ( Platforms for orchestration )
           - Selenium, TestNG      ( WebDriver + Testing )
Operations
      Configuration Management
           - Chef, Puppet, Ansible, Saltstack
      Containers
           - Docker
      Monitoring and Log
           - Nagios, Splunk


CI workflow
----------------
- Commit changes to source code by developers.
- CI server pulls that code and triggers a build depending on schedule configured in CRON format at jenkins.
- Build application is deployed on testing server for testing.
- After testing application is deployed on production server.
- Concerned teams are constantly notified about build and test results.

Benefits of CI
------------------
- Reduced risk
- Bugs and problems discovered in time
- System is deployable more frequently, enabling more user feedback

Best practices of CI
-------------------------
- Maintain single source repository
- Everyone commits to master branch everyday
- Automate build
- Keep build fast
- Make build self testing
- Fix broken builds immediately
- Everyone can see what's happening
- Automate deployment


Build (Maven)
--------------
- All dependencies are available at Maven Centralized Repo , which can be downloaded and used in our projects.
- Maven Lifecycle
  - Maven Compile         -> Java Classes, Compile -> (achieved by Maven Compiler plugin)
  - Maven Test            -> Test cases            -> (achieved by Maven Surefire plugin)
  - Maven Resource        -> JARs/WARs/EARs        -> (achieved by Maven Resource plugin)
- Maven has a POM (Page Object Model) XML file which contains      <dependencies> <dependency></dependency> </dependencies , <properties></properties>   etc...
  Although we have above plugins already included in project , still it's good practice to write all these plugins in POM.xml under <build> <plugins> <plugin></plugin> </plugins> </build>
- Maven Commands
  - $ mvn clean install        -> executes all three lifecycle procedures
  - $ mvn test                 -> executes only test lifecycle ie all methods with @Test in project
  - $ mvn package -DskipTests  -> skips test lifecycle


Jenkins
---------
- Jenkins is an orchestration and automation engine.
- It is extremely pluggable, with a lot of plug-ins emerged.
- The idea of CI is to merge code from individual developers into a project mulitple times per day and test continuously to avoid downstream problems.
- CD ensures that all merged code is always in a production ready state.
- Jenkins enables developers to automate this process as much as possible upto point of deployment
- STEPS
  ----------------------
  - Download jenkins.war from official website or use commands like "wget"  etc... 
  - On terminal, cd to this dir of downloaded jenkins.war and write command,      $ java -jar jenkins.war --httpPort=9090
    If this is first time , it will provide a password to be entered on home screen of Jenkins
  - open http://localhost:PORT on browser   (PORT = 8080 default or as specified)
  - install required plugins   Manage Jenkins --> Manage Plugins (eg: git plugin) --> search Available for required plugin or in Advanced (upload plugin file)
- Jenkins on TOMCAT
  -----------------------
  - Place jenkins.war in webapps dir of TOMCAT and start TOMCAT
- Jenkins root/HOME dir
  -----------------------
  - By default jenkins root dir ( where we have logs, configs, workspace, builds etc... ) is provided by default by jenkins. 
    Check from Manage Jenkins tab --> Configure Sysytem  once jenkins is running.
  - Copy all files from this old dir ( it might be hidden dir ) to new desired dir.
  - Change or add ENVIRONMENT variables JENKINS_HOME=<Path_to_new_dir>
- Jenkins CLI
  -----------------------
  - Start Jenkins
  - Manage Jenkins tab --> Configure Global Security --> Enable Security
  - Go to browser --> http://localhost:8080/cli/    this page will provide syntax for commands as per our instance
  - Download jenkins-cli.jar
  - cd to this .jar location and type command       java -jar jenkins-cli.jar -s <URL_for_Jenkins> <command>
    This will ask for a passphrase (SSH public key) which can be found under profile tab of user currently logged in --> Configure.
- Jenkins Create Users + Manage Roles
  ------------------------------------
  - Manage Jenkins tab --> Manage Users --> Create User
  - User Profile tab --> Configure
  - Role Strategy Plugin
    - Manage Jenkins --> Manage Plugins --> Available tab (Search for plugin and Download + install) or Advanced tab to upload plugin file
    - Manage Jenkins --> Cofigure Global Security --> Check Enable Security option --> Authorization (check ROLE BASED STRATEGY option)
    - Manage Jenkins --> Manage and Assign Roles --> Manage Roles
      Global roles   : Roles at global level     (eg: admin, employee)
      Project roles  : Roles at project level    (Define pattern (eg: Dev.* or Test.*) for which projects to assign roles) (eg: developer, tester)
    - Manage Jenkins --> Manage and Assign Roles --> Assign Roles
      Global roles   : Select role to assign as given in Manage Roles --> Global role tab     (eg: admin or employee)
      Project roles  : Select role to assign as given in Manage Roles --> Project role tab    (eg: developer or tester)
- Jenkins Configurations
   ---------------------------
  - Manage Jenkins --> Configure System
    Home directory           : home dir of jenkins (this can be changed , check "Jenkins root/HOME dir" step) , advance options will provide Workspace , Builds config
    System Message           : we can use HTML or Plain text ( as set in Manage Jenkins --> Configure Global Security --> Markup Formatter ) visible on dashboard of Jenkins
    Quiet Period             : number of seconds to wait before triggering job
    SCM checkout retry count : Max retry count to connect to SCM remote repo
    Restrict project Naming  : Naming pattern for new project to create
    Jenkins Location         : URL to use on browser for Jenkins UI, can be localhost or IP address
- JOBS (Project/Item) in Jenkins
  -------------------------------
  - New Item --> Select item configurations (maven/freestyle)
    - General         --> Project name, Description
    - SCM             --> Integrate remote repo (git, svn) .git URL, branch
    - Build Triggers  --> when/how to trigger job
       Trigger builds remotely          --> Provide auth token --> use URL provided to trigger job remotely from browser
       Build after other projects built --> Provide projects to watch (stable/unstable/fails)
       Build Periodically               --> CRON syntax followed
       Poll SCM                         --> Poll SCM (.git) integrated , uses CRON syntax to poll for new commit
    - Build           --> execute shell commands on code repo/files   (eg: cd /user/ra20024024/javaProj/; javac myfile.java; java myfile;)
    - Post Build Actions
       Build other projects             --> Provide project to build (stable/unstable/fails)
       Deploy WAR/EAR to container      --> Available via plugin
       Email Notifications
- CATLIGHT
  --------------------------------
  - It is a status notifier for CI tools like Jenkins, Travis etc.. which provides notifications on desktop for JOBS.
     Refer : https://catlight.io/
- Deploy to Container Plugin
  --------------------------------
  - If both Jenkins and TOMCAT are running on same machine , make sure to use different ports for these.
  - Make sure both are up and running plus configurations in case any connectionException occurs.
  - Search for this plugin in Manage Jenkins --> Manage Plugin --> Available --> Search/Download/Install  "Deploy to Container Plugin"
  - In Post Build actions of Item/JOB , choose Deploy WAR/EAR to container. Choose your WAR name (as in <workspace_path>/<project> of Jenkins)
  - For TOMCAT credentials to be used with Jenkins , go to tomcat-users.xml to check and use, <user username="" password="" roles=""></user>
- EMAIL Notifications
  ---------------------------------
  - Refer:    https://www.arclab.com/en/kb/email/list-of-smtp-and-pop3-servers-mailserver-list.html     for SMTP details.
  - Manage Jenkins --> Configure System --> Email Notifications (Advanced). Provide SMTP details from where to send.
  - Inside JOB --> Configure --> Post Build Actions --> Email notification
- Jenkins Delivery PIPELINE
  ---------------------------------
  - To Visualize Chained Jobs.
  - Download/Install Delivery Pipeline Plugin
  - Add new View/Tab on Jenkins Dashboard and select Delivery Pipeline View.
  - Configure this view , component and add initial job , Instances to show , Enable rebuild , Enable start , Enable Build Time   etc...
- Jenkins Build PIPELINE
  ---------------------------------
  - To Visualize Chained Jobs.
  - Download/Install Build Pipeline Plugin
  - Add new View/Tab on Jenkins Dashboard and select Build Pipeline View.
  - Configure this view , initial job , Instances to show , Console output  etc...
- Jenkins Blue Ocean UI
  ---------------------------------
  - Works only on Jenkins version 2.7 or above.
  - A new UI for Jenkins that provides interactive view for Jenkins pipeline and jobs.
  - Download/Install Blue Ocean plugin.
  - A button will appear on dashboard to switch UI to Blue Ocean UI and similarly in Blue Ocean to switch to classic view.
- Poll Mail Box Trigger
  ---------------------------------
  - Trigger Build on receiving a mail
  - Download/Install Poll Mail Box Trigger plugin
  - Configure plugin under Build Triggers
- Build Monitor View plugin
  ---------------------------------
  - Shows highly visible status of selected jobs.
  - Download/Install Build monitor view plugin.
  - Add new View/Tab on Jenkins Dashboard and select Build Monitor View
  - Configure plugin.


Continuous Deployment (CD)
---------------------------
- It is a business specific need and might not always required to be performed.
- Blue Green deployment method
  - A technique to reduce downtime and risk by running two identical production environments called Blue and Green
  - At anytime only one of environments is live , serving all production traffic.
- Rollback also is an important part of automated deployment.

CD enablers
----------------
- Comprehensive configuration management
- Containers
- Continuous Testing/Monitoring

Benefits of CD
--------------------
- Low risk releases
- Faster time to market
- Higher quality
- Lower costs
- Better products


CM ( Configuration Management )
--------------------------------------------
- To establish and maintain integrity of products of software project.
- It refers to discipline for evaluating, coordinating, approving or disapproving and implementing changes in artifacts that are used to construct and maintain software.
- An artifact is a piece of hardware or software or documentation.
- This makes use of IAC (Infrastructure as Code).
- It controls changes , if a software upgrade or configuration caused glitch , it can be rolled back easily using CM tools.
- Without CM, a common issue of code working on Dev environment and not working on Production environment may occur.
- It allows to scale the system by having one control machine and others can be remote machines to scale to.

Ansible
----------
- Ansible uses Playbook which uses YAML (.yml) files.
- It does not require any agents whereas Chef or Puppet does require , It is built on python , It uses SSH.
- It uses Push based architecture whereas Chef or Puppet uses Pull based architecture.
- YAML (.yml) files
  - It starts with   ---  and ends with   ...
  - Lists are also written in YAML each element in new line
  - specific tags are specified in YAML like name, hosts, vars, tasks
- STEPS
  - genearte SSH key using `ssh-keygen`
  - modify HOST inventory file located at /etc/ansible/hosts to specify group or individual HOST
  - copy SSH key to remote machine using `ssh-copy-id -i HOSTNAME`
  - check if remote machine or group is up and running as mentioned in HOST inventory file using `ansible -m ping test-servers`
  - create a YAML (.yml) file
  - run playbook with this YAML file using `ansible-playbook myfile.yml`

Chef
----------
- Recipe is a configuration script used in Chef.
- Chef is written in Ruby and recipes are written in Ruby too.
- Collection of scripts (recipes) is called CookBook.
- Tool with which scripts created, it is called Knife.
- It makes use of Pull based approach where nodes poll server and pull configurations.
- Chef Architecture
  Three entities Workstation, Chef Server, Nodes.
  Workstation is like development machine or local chef repository from where configurations are sent to Chef Server.
  Chef server is like remote repository or a mirror for Nodes which tells them (nodes) whether they are inline with configurations desired.
  Nodes (chef clients) are target systems which pulls configuration from Chef Server that needs to be applied to them.
- To install chef , download Chef Development Kit (CDK).

Puppet
----------
- It makes use of Pull based approach.
- Puppet Architecture
  It has a Master-Slave architecture.
  Nodes (slaves or agent) send data about itself to Puppet Master , ie it polls master.
  This data is then compiled by Puppet master and configuration data is sent back to node.
  Node then sends back a confirmation to Master that configuration is complete and it is visible on dashboard.
- Resources are files, packages that define some aspect of system.
  eg: <resource_type> { '<resource_name>' : <attribute> => '<value>' }
- Classes are groups of resources. A resource defines a single file or package but a class describes everything needed to configure entire system.
  eg: class <example_class> { ... }
- Manifests are Puppet programs which have extensions as .pp
- Modules are collection of manifests and data.
  To add module to puppet , place it in   `/etc/puppet/modules`   directory
  
  
LOG and MONITORING
------------------------------------
Nagios
------------
- It is a monitoring software application to monitor (health check) computer sysytems , networks and entire infrastructure.
- It provides alerts over SMS, Phone, Email.
- It can provide monitoring for 
  server and network nodes, 
  services (application and databases), 
  ups backup system, 
  bio metric identification system, 
  temperature and humidity control system
  cctv systems
  storage subsystem (NAS-Network Attached Storage and SAN-Storage Area Network)
- Nagios has two flavors
  Core - Open Source
  Xi   - Commercial
- Attempt to ping the machines is considered as Soft state.
  Attempt where an alert is generated is considered as Hard state.
  
Splunk
------------
- It is a tool for exploring/analyze real time logs.
  It provides real time alerts/notifications.
  It provides historical data analysis as well.
  It provides real time server monitoring.
- Splunk Components
  forwarders which forward the logs to indexers/peer nodes.
  indexers which store the logs but it cannot be used to search logs , so it forwards it to search heads/cluster members.
  search heads provide search in these logs.
  apart from this it has Deployment server, Cluster master, Deployer


CONTAINERIZATION
-------------------------------------
Virtualization vs Containerization
------------------------------------
- In virtualization we have a software called Hypervisor which will create multiple GUEST OS over HOST OS.
  Each of these GUEST OS are a VM (app plus guest OS) and they donot use HOST OS which is an overhead over HOST platform.
  Each of VM have a defined memory which does not change as per application needs resulting in wastage and redundant memory.
- In containerization we have Container Engine (Docker Engine) which uses containers.
  Each of continers (app plus libs) uses memory as per application needs from OS resulting in efficient use of HOST platform.
  It can run on any machine that has Docker installed which prevents need to configure and build app multiple times on different platforms.
  Containers are processes that are shared OS processes. This is verified by `$ docker top <container_name>` and `$ ps aux`, both show same UID | PID etc..


KUBERNETES or K8S
---------------------
PODS group containers together.
SERVICES make PODS available to others.
`$ kubectl` command used for scripting operations on K8S


EC2 CONTAINER SERVICE (ECS)
--------------------------------
TASK DEFINITIONS, are set of containers that run together, just like PODS in K8S.
TASKS, when container actually starts running now.
SERVICES, ensure that task is running all time and expose it to NETWORK.


AWS FARGATE
----------------
KUBERNETES ENGINE by GOOGLE CLOUD
----------------------------------------
AZURE KUBERNETES SERVICE (AKS) by MICROSOFT
---------------------------------------------

